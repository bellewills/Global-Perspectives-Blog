---
external: false
title: "How We Hack The Planet // Jake Davis " 
date: 2025-04-23


---

#### Brief Summary of the Talk 
Jake Davis, formerly known as Topiary, offered a deeply personal account of his time as a member of LulzSec and Anonymous, two of the most well-known hacktivist groups. His talk wasn’t just about hacking in the technical sense but explored the emotional and ethical dimensions of why people hack—especially when confronting corporate and governmental abuses of power. Davis openly acknowledged the legal repercussions of his actions but framed hacking as a form of activism, something I hadn’t fully considered before. His story raised profound questions about justice, power, and the role of hackers in holding authority accountable when traditional systems fail.

What struck me, watching this talk straight after the IBM quantum computing session, was how these two worlds felt like polar opposites—one about cutting-edge technology and securing the future, the other about challenging current systems when they fail us. And yet, the more I reflected, the more I realised they were two sides of the same coin. Quantum computing could either empower or oppress—depending on who controls it. Hackers like Davis? They make sure we don’t forget that.


#### 1) What was the most surprising or thought-provoking idea from the talk?
The most surprising idea was Davis’s portrayal of hacking as a moral duty, a way of fighting back against systems that exploit or oppress. This challenged my perception that hacking is just about causing chaos or stealing data. I’ve always seen hackers as the villains in the cybersecurity story, but Davis flipped that narrative. He painted hackers—at least some of them—as digital activists, whistleblowers, and defenders of those without power.

This made me question: Why have I been conditioned to view hackers solely as threats? Is it because mainstream narratives tend to demonise those who disrupt the status quo? I realised that perhaps corporations and governments benefit from portraying all hackers as criminals, because it distracts from the systemic issues being exposed.

That’s what made Davis’s story so powerful—it forced me to confront my own assumptions about good and bad in cybersecurity. Maybe the line between criminal and activist isn’t as clear as I thought.

#### 2) What questions or curiosities did this lecture spark for you? If you asked the speaker a question, what was their response?
One question that stuck with me is: Where should we draw the ethical line in hacktivism? If legal frameworks fail to protect the vulnerable, who gets to decide when hacking is justified?

I kept thinking about whistleblower protections. Shouldn’t ethical hackers, who expose flaws for the public good, be afforded similar protections? I’d love to ask Jake: What kind of legal framework could protect ethical hackers without enabling malicious actors? Would he argue for formalising hacktivism as a legitimate form of protest?

I imagine he’d say that the current legal system is too rigid—that it doesn’t differentiate intent, treating ethical hackers and malicious cybercriminals the same. This made me reflect on how broken the system is if it can’t distinguish between fighting for justice and committing harm. It left me wondering whether we need a new social contract for cyberspace, one that recognises the nuances of digital activism.

In future, I’d like to explore work like Gabriella Coleman’s ethnography on Anonymous and legal proposals around responsible disclosure, to understand how intent and harm are weighed in policy debates.

#### 3) What made you optimisitc about the future from this talk?
Surprisingly, this talk filled me with a quiet sense of hope. Seeing how Davis transformed his skills from causing disruption to advocating for ethical hacking showed me that people can change. More importantly, it proved that hacking itself isn’t inherently bad—it’s a tool, and like any tool, it can be used to harm or to protect.

What makes me feel hopeful is the growing recognition of ethical hacking as a legitimate, even essential, part of cybersecurity. The rise of bug bounty programs, ethical hacker certifications, and collaborations between companies and hackers shows that the world is slowly embracing this mindset.

I realised that activism and cybersecurity don’t have to be opposites. In fact, they can and should intersect—because systems aren’t neutral. They’re built by people, for people, and ethical hackers ensure those systems serve everyone, not just the powerful.

#### 4) What key ideas did the speaker highlight and why are they significant with respect to trends in computing?
Jake emphasised that hackers are often the first to spot system vulnerabilities, long before companies or governments notice. This is significant, especially when tied to current trends like the expansion of digital infrastructure, data collection, and the integration of AI. As systems grow in complexity (something Charter’s talk on scaling space software highlighted), vulnerabilities multiply.

This made me think about Dr Gardham’s focus on cryptography—he talked about securing systems from the ground up, using maths and code. Jake, on the other hand, demonstrated how real-world systems fail at the human level—where greed, power, and corruption introduce vulnerabilities no amount of encryption can fix.

Both talks underscored the need for holistic security—technical and ethical. It’s not enough to lock down data with cryptography if the power structures around that data remain exploitative.

Thinking about this in the context of the IBM quantum talk, I realised that hackers will play a critical role in testing quantum systems too. As quantum encryption rolls out (something IBM is working hard on), hackers will be the ones probing it, ensuring it holds up in the real world. Just as Davis exposed the flaws in existing structures, future hackers will be testing the limits of quantum cryptography. This ties Gardham’s post-quantum focus and IBM’s quantum development to Davis’s activist approach. It made me ask: If we’re building quantum systems, who will hold them accountable?

This echoes historical moments in hacking, like the release of the first “white hat” hacking tools in the late 1980s or the formation of the Electronic Frontier Foundation in 1990. As systems grow more complex, hackers have continually played the role of early warning systems.

#### 5) What ethical challenges might arise from the ideas covered in this talk, and how might they impact technology use?
The biggest ethical challenge is how we regulate hacktivism without stifling it. When hackers act in the public interest, exposing abuses of power, I believe that’s necessary. But without clear boundaries, there’s a risk of collateral damage—like innocent people being caught in the crossfire.

This talk made me compare Jake’s actions with Mirim Sturdee’s approach to risk visualisation. Sturdee sketched out what could go wrong. But Jake acted on those risks—sometimes without a safety net, without formal structures to ensure no harm would come to bystanders.

That left me asking: Is it better to act and risk unintended harm or stay passive while injustice continues? This is the core tension in hacktivism. It reminded me of Charter’s access control dilemmas—too much control stifles innovation, but too little invites chaos. The same is true here.

#### 6) Did you agree or disagree with the ideas the speaker covered? Why? Why not?
I agreed with Jake’s belief that hacktivism is necessary in a world where power often goes unchecked. His message that groups like Anonymous fill a void—acting when governments ignore corruption or corporations exploit people—really resonated with me.

I believe that activism matters most when traditional systems fail. Without groups like Anonymous, many injustices would stay hidden. And yet, I still wrestle with the methods they use. While I admire the courage it takes to challenge power, I worry about collateral damage—innocent people caught in the middle of cyber attacks.

But then I ask myself: If not them, who? Who holds the powerful accountable when laws protect corporations more than people? My belief is that hacktivism is needed, but it should be done with conscience—a fight for justice, not revenge.

#### 7) What role do you think the technology or concepts from this talk could play in influencing society in future?
I believe hacktivism will increasingly shape digital rights. As corporate influence grows and governments expand surveillance, we’ll need ethical hackers to push back, defend privacy and expose abuse. This complements Gardham’s work on encryption—while he protects data at a technical level, hackers ensure that the systems around that data aren’t abused.

In a world where AI and IoT blur the lines between technology and daily life, ethical hackers will become key watchdogs—protecting the public interest in ways laws can’t keep up with.

After the quantum computing talk, I felt excited about the possibilities of technology. But Davis reminded me that possibilities come with power, and power needs checks and balances. Quantum technology could transform society—but hacktivists will be vital in ensuring it serves everyone, not just corporations or governments. It’s a reminder that no system is unbreakable, and perhaps hackers are the immune system of technology, just as Keren Elazari described hackers in her TED talk.

#### 8) What connections can you make between this lecture and others in the series? 
Jake’s talk contrasts but also complements Gardham’s focus on cryptography. Gardham secures the code, but Davis exposes the systems built around that code. Both approaches are necessary—one keeps the walls strong, and the other questions what’s inside those walls.

Compared to Charter, this talk felt like the flip side of scalability. Charter built systems to scale, but Davis reminded us that bigger systems mean bigger vulnerabilities—and more power in fewer hands. The more complex the system, the more hackers need to step in to ensure fairness.

With Sturdee, the contrast is clearer. She visualised problems, and Davis acted on them. Both are valid approaches, but Davis’s story hit me emotionally—because it felt urgent, real, and human.

This interplay between quantum security and hacktivism created a bridge between Davis’s talk and the IBM session. Where IBM is building the future of cryptography, Davis’s world ensures it stays honest. Hackers like him will pressure-test those quantum systems, finding new vulnerabilities we haven’t even imagined yet. Both Gardham and IBM spoke about post-quantum encryption, but Davis’s talk made me wonder—will that ever truly be enough? Or will activists always find a way in, because no system is perfect?

#### 9) For the assignment, you will present the outline of a future opportunity based on the topics covered in these talks. What ideas from the talk today do you think you could discuss with your groups to use in the assessment? If not using ideas from this talk for the assignment, why not?

While Jake Davis’s talk doesn’t give me the technical tools for my quantum-safe encryption project (inspired by Gardham), it grounds the why behind my project. His activism-first approach reminds me that encryption and security aren’t just about technology—they’re about people’s rights, privacy, and protection from abuse.

For the assignment, I’d use Gardham’s cryptography as the core technical concept, but Davis’s hacktivism as context. Why do we need quantum-safe encryption? Because hackers will expose flaws if we don’t build secure, ethical systems. They are the testers of digital integrity—whether we invite them in as ethical hackers or they come knocking uninvited.


https://www.youtube.com/watch?v=75gNBrZH2WA - Instead of CAID talk - Approved by Corey

