---
external: false
title: "Hackmasters // Saher Sidhom " 
date: 2025-05-06

--- 

#### Brief Summary of the Talk 
 
The HackMasters talk, led by Saher Sidhom —described as one of the best strategic minds—explored speculative and near-future technologies that blur the lines between AI, ethics, surveillance, and cognitive enhancement. Saher discussed concepts such as downloading the human brain, copying insect neural pathways, and implanting microchips that enable AI to scan our environment and dictate our needs. The talk warned of a future where free will might erode under the control of AI. It also proposed a dystopian world, Mindopoly, where political influence and corporate power exploit implanted prediction chips, raising pressing concerns about manipulation, power, and identity. While the talk itself didn’t focus on the history of computing, it implicitly built on it, pushing us to question what comes next.

#### 1) What was the most surprising or thought-provoking idea from the talk?
“They don’t want to create robots—they want to make you the robots.” That quote shown at the beginning of the talk hit hard. It reframes AI from a tool that serves us to a force that controls us. It made me think about how early computing—rooted in logic and problem-solving—was designed to extend human ability, not overwrite it. But now, we're at a point where technology may redefine what it means to be human.

#### 2) What questions or curiosities did this lecture spark for you? If you asked the speaker a question, what was their response?
It made me wonder: if these chips and prediction AIs become common, how do we regulate them? Who decides what "truth" the chip tells us? I would have asked: “Can we ever build embedded tech that enhances human judgement without replacing it?” It’s a question grounded in the history of computing—from Alan Turing’s foundational work on machine logic, which never assumed emotional manipulation, to today’s emotion-sensing algorithms that claim to know us better than we know ourselves.

In future, I’d like to read works like Shoshana Zuboff’s “The Age of Surveillance Capitalism” and explore current EU AI regulatory proposals to better understand how these systems might be governed.

#### 3) What made you optimistic about the future from this talk?
Honestly, the technology itself didn’t fill me with optimism—but the debate did. The talk challenged us to consider our role in shaping the future. Historically, computing has evolved through public discourse and ethical resistance—from the Free Software Movement to early AI ethics frameworks. This talk continued that tradition of critical questioning, which gave me hope.

#### 4) What key ideas did the speaker highlight, and why are they significant with respect to trends in computing?
Saher focused on predictive chips, sensory AI, and embedded microtechnologies. These aren’t just speculative—they’re the next stage of ambient computing. If we look at the history of computer science, we’ve moved from mainframes to desktops to smartphones—and now to wearables and implants. This is the logical progression, but Saher’s framing turned it into a warning: the smaller and more “invisible” the tech, the more control it may quietly exert.

This shift follows the historical trajectory outlined in our class timeline—from room-sized ENIACs in the 1940s to today’s neural implants and ambient AI. Saher’s talk fits into that arc, but warns that what started as augmentation could become quiet control.


#### 5) What ethical challenges might arise from the ideas covered in this talk, and how might they impact technology use?
Surveillance, manipulation, consent, and misinformation—these are the central ethical issues. The idea of AI predicting your vote and being manipulated by corporations reminded me of the history of cybernetics and behavioural computing. In the 1940s, Norbert Wiener’s theories aimed to create adaptive systems; however, today’s systems often feel more like tools of persuasion. With chips feeding biased predictions into our thoughts, it’s not just your data being stolen—it’s your agency.

Some argue that predictive AI can help streamline decision-making and enhance productivity if designed with transparency. Others warn it may reinforce bias and reduce autonomy. I see both sides, but lean toward caution—especially when manipulation hides behind convenience.

#### 6) Did you agree or disagree with the ideas the speaker covered? Why? Why not?
I agree with the idea that we’re heading into dangerous territory with AI and brain-tech fusion, especially without accountability. But I wished the talk touched more on the roots of computing—the ideals of logical clarity, universal access, and human-centred design that early computer scientists fought for. We’ve drifted from that. The talk served as a wake-up call, but I think we also need to remember the values that started this field.

#### 7) What role do you think the technology or concepts from this talk could play in influencing society in future?
If implemented, technologies like mind chips and embedded predictive AI could alter democracy, identity, and social power structures. It’s a natural—if alarming—next step in the trajectory of ubiquitous computing. As we move beyond wearable tech to internalised tech, this talk warned of a society that feels free but isn’t. It reminded me of how early computers were tools for calculation and liberation—but what if now they become tools of compliance?

#### 8) What connections can you make between this lecture and others in the series? 
This talk echoed Jake Davis’s concerns about systemic abuse of technology and mirrored Gardham’s worry about trust in encryption. The dystopian prediction chip in Mindopoly felt like the next stage after today’s data mining. It also contrasted Sturdee’s speculative sketches—hers felt hopeful, and this felt urgent. Across the series, we’ve moved from exploration (space), imagination (HCI), and protection (cybersecurity) into manipulation and control. Together, they show how computing history—once driven by empowerment—is now being redefined by influence and persuasion.

#### 9) For the assignment, you will present the outline of a future opportunity based on the topics covered in these talks. What ideas from the talk today do you think you could discuss with your groups to use in the assessment? If not using ideas from this talk for the assignment, why not?
The idea of a political prediction chip could be turned into a speculative artefact for our group project. In this cautionary future, people believe they’re making informed choices, but they’re being algorithmically steered. We could visualise how the UI of such a chip might look, including warnings, false data, and ethical red flags. Even if we don’t use it, this talk offers rich ideas for exploring manipulation, consent, and embedded computing—all through a lens that forces us to revisit what computing was meant to be.
   




